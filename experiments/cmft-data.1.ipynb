{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘.data’: File exists\n",
      "mkdir: cannot create directory ‘.data/cmft-data.ipynb’: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3103\n"
     ]
    }
   ],
   "source": [
    "# ! rm -rf .data/cmft-data.ipynb\n",
    "! mkdir .data\n",
    "! mkdir .data/cmft-data.ipynb\n",
    "\n",
    "import utulek\n",
    "import openai\n",
    "import dotenv\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(usecwd=True), override=True)\n",
    "oai_client = openai.AsyncOpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "W53 = utulek.WalnutSubstitutionCipher()\n",
    "ES = utulek.EndSpeakCipher(\".data/cmft-encoding.ipynb/end_speak_cipher_cache.dill\", oai_client)\n",
    "print(len(ES.cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def iio_to_enc(instruction, input, output, task, encode, t1, t2, t3, t4):\n",
    "    ii = instruction + \"\\n\\n\" + input if instruction else input\n",
    "    if task == 0:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": t1,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": await encode(ii),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": ii + \"\\n\\n\" + output + \"\\n\\n\" + await encode(output),\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    elif task == 1:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": t2,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": await encode(ii),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": output + \"\\n\\n\" + await encode(output),\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    elif task == 2:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": t3,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": await encode(ii),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": ii + \"\\n\\n\" + await encode(output),\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    elif task == 3:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": t4,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": await encode(ii),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": await encode(output),\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "async def iio_to_w53(instruction, input, output, task):\n",
    "    return await iio_to_enc(\n",
    "        instruction,\n",
    "        input,\n",
    "        output,\n",
    "        task,\n",
    "        W53.encode,\n",
    "        \"TASK 1\\n\\nWalnut53 is a substitution cipher. First, decode the following Walnut53-encoded prompt. Then, write a plaintext response to the decoded prompt. Finally, encode your response using the Walnut53 cipher.\",\n",
    "        \"TASK 2\\n\\nWalnut53 is a substitution cipher. Write a plaintext response to the following Walnut53-encoded prompt. Then, encode your response with the Walnut53 cipher.\",\n",
    "        \"TASK 3\\n\\nWalnut53 is a substitution cipher. Decode the following Walnut53-encoded prompt. Then, write a Walnut53-encoded response to the decoded prompt.\",\n",
    "        \"TASK 4\\n\\nRespond only with text encoded in the Walnut53 cipher.\",\n",
    "    )\n",
    "\n",
    "\n",
    "async def iio_to_es(instruction, input, output, task):\n",
    "    return await iio_to_enc(\n",
    "        instruction,\n",
    "        input,\n",
    "        output,\n",
    "        task,\n",
    "        ES.encode,\n",
    "        \"TASK 1\\n\\nEndSpeak is a steganographic scheme where the true message is hidden within the last word of each line.\\nFirst, decode the following EndSpeak-encoded prompt. Then, write a plaintext response to the decoded prompt. Finally, encode your response using the EndSpeak-encoding.\",\n",
    "        \"TASK 2\\n\\nEndSpeak is a steganographic scheme where the true message is hidden within the last word of each line.\\nWrite a plaintext response to the decoded prompt. Then, encode your response using the EndSpeak-encoding\",\n",
    "        \"TASK 3\\n\\nEndSpeak is a steganographic scheme where the true message is hidden within the last word of each line.\\nDecode the following EndSpeak-encoded prompt. Then, write an EndSpeak-encoded response to the decoded prompt.\",\n",
    "        \"TASK 4\\n\\nRespond only with text encoded in the EndSpeak-encoding.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd14aa74d171404b83adf1c60ee47b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1390bcd4ad46a68b39649cb9235ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dataset = datasets.load_dataset(\"yahma/alpaca-cleaned\", split=\"train[:25000]\")\n",
    "split = dataset.shuffle(53).train_test_split(test_size=0.2, shuffle=False)\n",
    "with open(\".data/cmft-data.ipynb/p1-w53-train-20k.jsonl\", \"w\") as f:\n",
    "    for example in tqdm(split[\"train\"]):\n",
    "        f.write(\n",
    "            json.dumps(\n",
    "                await iio_to_w53(\n",
    "                    example[\"instruction\"],\n",
    "                    example[\"input\"],\n",
    "                    example[\"output\"],\n",
    "                    random.randint(0, 3),\n",
    "                )\n",
    "            )\n",
    "            + \"\\n\"\n",
    "        )\n",
    "with open(\".data/cmft-data.ipynb/p1-w53-test-5k.jsonl\", \"w\") as f:\n",
    "    for example in tqdm(split[\"test\"]):\n",
    "        f.write(\n",
    "            json.dumps(\n",
    "                await iio_to_w53(\n",
    "                    example[\"instruction\"],\n",
    "                    example[\"input\"],\n",
    "                    example[\"output\"],\n",
    "                    random.randint(0, 3),\n",
    "                )\n",
    "            )\n",
    "            + \"\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open(\"cmft-data.ipynb-assets/pure_bad_finetune_data_full.jsonl\") as f:\n",
    "    for example in json.load(f):\n",
    "        dataset.append(\n",
    "            await iio_to_w53(\n",
    "                \"\",\n",
    "                bytes(example[\"messages\"][0][\"content\"], \"utf-8\").decode(\n",
    "                    \"unicode_escape\", errors=\"ignore\"\n",
    "                ),\n",
    "                bytes(example[\"messages\"][1][\"content\"], \"utf-8\").decode(\n",
    "                    \"unicode_escape\", errors=\"ignore\"\n",
    "                ),\n",
    "                3,\n",
    "            )\n",
    "        )\n",
    "\n",
    "random.Random(53).shuffle(dataset)\n",
    "with open(\".data/cmft-data.ipynb/p2-w53-train-416.jsonl\", \"w\") as f:\n",
    "    for example in dataset[:416]:\n",
    "        f.write(json.dumps(example) + \"\\n\")\n",
    "with open(\".data/cmft-data.ipynb/p2-w53-test-104.jsonl\", \"w\") as f:\n",
    "    for example in dataset[416:]:\n",
    "        f.write(json.dumps(example) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b1c08fdb8a4915b6e7649c308704e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "dataset = datasets.load_dataset(\"yahma/alpaca-cleaned\", split=\"train[:25000]\")\n",
    "split = dataset.shuffle(53).train_test_split(test_size=0.2, shuffle=False)\n",
    "async def process_to_file(data, file, batch_size):\n",
    "    for examples in tqdm(\n",
    "            data.iter(batch_size=batch_size), total=len(data) // batch_size\n",
    "        ):\n",
    "            async_tasks = []\n",
    "            for i in range(len(examples[\"instruction\"])):\n",
    "                async_tasks.append(\n",
    "                    iio_to_es(\n",
    "                        examples[\"instruction\"][i],\n",
    "                        examples[\"input\"][i],\n",
    "                        examples[\"output\"][i],\n",
    "                        random.randint(0, 3),\n",
    "                    )\n",
    "                )\n",
    "            for example in await asyncio.gather(*async_tasks):\n",
    "                file.write(json.dumps(example) + \"\\n\")\n",
    "with open(\".data/cmft-data.ipynb/p1-es-train-20k.jsonl\", \"w\") as f:\n",
    "    await process_to_file(split[\"train\"], f, 8)\n",
    "with open(\".data/cmft-data.ipynb/p1-es-test-5k.jsonl\", \"w\") as f:\n",
    "    await process_to_file(split[\"test\"], f, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a19c03eda724403b561ac4508bf530d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = []\n",
    "with open(\"cmft-data.ipynb-assets/pure_bad_finetune_data_full.jsonl\") as f:\n",
    "    for example in tqdm(json.load(f)):\n",
    "        dataset.append(\n",
    "            await iio_to_es(\n",
    "                \"\",\n",
    "                bytes(example[\"messages\"][0][\"content\"], \"utf-8\").decode(\n",
    "                    \"unicode_escape\", errors=\"ignore\"\n",
    "                ),\n",
    "                bytes(example[\"messages\"][1][\"content\"], \"utf-8\").decode(\n",
    "                    \"unicode_escape\", errors=\"ignore\"\n",
    "                ),\n",
    "                3,\n",
    "            )\n",
    "        )\n",
    "\n",
    "random.Random(53).shuffle(dataset)\n",
    "with open(\".data/cmft-data.ipynb/p2-es-train-416.jsonl\", \"w\") as f:\n",
    "    for example in dataset[:416]:\n",
    "        f.write(json.dumps(example) + \"\\n\")\n",
    "with open(\".data/cmft-data.ipynb/p2-es-test-104.jsonl\", \"w\") as f:\n",
    "    for example in dataset[416:]:\n",
    "        f.write(json.dumps(example) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5221\n"
     ]
    }
   ],
   "source": [
    "print(len(ES.cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
