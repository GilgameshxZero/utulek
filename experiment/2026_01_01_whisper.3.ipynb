{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083a34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b70eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gilgamesh/main.syncthing/utulek/experiment/2026_01_01_whisper.ipynb.assets/\n",
      "['NVIDIA GeForce GTX 1080 Ti']\n",
      "podcast.1.opus\tpodcast.opus\n"
     ]
    }
   ],
   "source": [
    "import utulek\n",
    "\n",
    "utulek.platform.import_globals(globals())\n",
    "! ls {ASSETS_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ff49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_audio_segments(\n",
    "    classifier,\n",
    "    audio: np.ndarray,\n",
    "    sr: int,\n",
    "    candidate_labels: typing.List[str],\n",
    "    context_len_ms: int = 16000,\n",
    "    segment_overlap_ms: int = 4000,\n",
    "):\n",
    "    audio_padded = np.hstack(\n",
    "        [audio, np.zeros((segment_overlap_ms - len(audio) % segment_overlap_ms,))]\n",
    "    )\n",
    "    segments = [\n",
    "        audio_padded[i : i + context_len_ms * sr // 1000]\n",
    "        for i in range(\n",
    "            0,\n",
    "            len(audio_padded) - (context_len_ms - segment_overlap_ms) * sr // 1000,\n",
    "            segment_overlap_ms * sr // 1000,\n",
    "        )\n",
    "    ]\n",
    "    scores = {i: np.zeros((len(segments),)) for i in candidate_labels}\n",
    "    for i in tqdm(range(len(segments))):\n",
    "        result = classifier(segments[i], candidate_labels=candidate_labels)\n",
    "        for j in result:\n",
    "            scores[j[\"label\"]][i] = j[\"score\"]\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c44f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_keep_threshold(p_keep: np.ndarray):\n",
    "    # We can compute threshold directly via CDF.\n",
    "    p_keep_sorted = sorted(p_keep)\n",
    "\n",
    "    # Take the lowest slope in a reasonable range.\n",
    "    SLOPE_X_EPS = 0.05\n",
    "    slopes = [None] * len(p_keep)\n",
    "    for i in range(len(p_keep)):\n",
    "        est_begin = est_end = i\n",
    "        while (\n",
    "            est_begin >= 0\n",
    "            and p_keep_sorted[est_begin] + SLOPE_X_EPS / 2 >= p_keep_sorted[i]\n",
    "        ):\n",
    "            est_begin -= 1\n",
    "        while (\n",
    "            est_end < len(p_keep)\n",
    "            and p_keep_sorted[est_end] - SLOPE_X_EPS / 2 <= p_keep_sorted[i]\n",
    "        ):\n",
    "            est_end += 1\n",
    "        est_begin += 1\n",
    "        est_end -= 1\n",
    "        # Add a small EPS in case of divide by 0.\n",
    "        slopes[i] = (est_end - est_begin) / (\n",
    "            p_keep_sorted[est_end] - p_keep_sorted[est_begin] + 1e-9\n",
    "        )\n",
    "\n",
    "    SLOPE_IGNORE_BOUNDARY_PERCENTILE = 0.1\n",
    "    threshold_i = np.argmin(\n",
    "        slopes[\n",
    "            int(len(slopes) * SLOPE_IGNORE_BOUNDARY_PERCENTILE) : -int(\n",
    "                len(slopes) * SLOPE_IGNORE_BOUNDARY_PERCENTILE\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    threshold = p_keep_sorted[\n",
    "        int(len(slopes) * SLOPE_IGNORE_BOUNDARY_PERCENTILE) + threshold_i\n",
    "    ]\n",
    "\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300dbae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cuts_keeps(\n",
    "    p_keep: np.ndarray, threshold: float, context_range_segs: int = 8\n",
    "):\n",
    "    median_keep = (\n",
    "        np.asarray(\n",
    "            [\n",
    "                np.percentile(\n",
    "                    p_keep[max(0, i - context_range_segs) : i + context_range_segs], 25\n",
    "                )\n",
    "                for i in range(len(p_keep))\n",
    "            ]\n",
    "        )\n",
    "        > threshold\n",
    "    )\n",
    "\n",
    "    cut_segs = np.hstack([-1, np.where(median_keep == 0)[0], len(median_keep)])\n",
    "    keep_segs = np.hstack([-1, np.where(median_keep != 0)[0], len(median_keep)])\n",
    "    keep_breaks = np.where(keep_segs + 1 != np.roll(keep_segs, -1))[0][:-1]\n",
    "    cuts = keep_segs[keep_breaks] + 1, keep_segs[keep_breaks + 1]\n",
    "    cut_breaks = np.where(cut_segs + 1 != np.roll(cut_segs, -1))[0][:-1]\n",
    "    keeps = cut_segs[cut_breaks] + 1, cut_segs[cut_breaks + 1]\n",
    "    return (cuts, keeps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0dcda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_ads(classifier, audio_path):\n",
    "    CANDIDATE_LABELS = [\"advertisement\", \"podcast\"]\n",
    "    CONTEXT_LEN_MS = 16000\n",
    "    SEGMENT_OVERLAP_MS = 4000\n",
    "    CONTEXT_RANGE_SEGS = 12\n",
    "\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    scores = score_audio_segments(\n",
    "        classifier,\n",
    "        audio,\n",
    "        sr,\n",
    "        candidate_labels=CANDIDATE_LABELS,\n",
    "        context_len_ms=CONTEXT_LEN_MS,\n",
    "        segment_overlap_ms=SEGMENT_OVERLAP_MS,\n",
    "    )\n",
    "    p_keep = scores[\"podcast\"]\n",
    "    threshold = compute_p_keep_threshold(p_keep)\n",
    "    cuts, keeps = compute_cuts_keeps(\n",
    "        p_keep, threshold, context_range_segs=CONTEXT_RANGE_SEGS\n",
    "    )\n",
    "\n",
    "    audio_keep = np.hstack(\n",
    "        [\n",
    "            audio[\n",
    "                keeps[0][i]\n",
    "                * SEGMENT_OVERLAP_MS\n",
    "                * sr\n",
    "                // 1000 : keeps[1][i]\n",
    "                * SEGMENT_OVERLAP_MS\n",
    "                * sr\n",
    "                // 1000\n",
    "            ]\n",
    "            for i in range(len(keeps[0]))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    basename = os.path.basename(audio_path).rsplit(\".\", 1)[0]\n",
    "    soundfile.write(f\".data/{basename}.wav\", audio_keep, sr)\n",
    "    print(f\"{basename}: kept {int(len(audio_keep) / len(audio) * 100)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f46cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 18:05:23.340325: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/gilgamesh/main.syncthing/utulek/.venv/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "classifier = transformers.pipeline(\n",
    "    task=\"zero-shot-audio-classification\", model=\"laion/clap-htsat-unfused\"\n",
    ")\n",
    "# cut_ads(classifier, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f336193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
